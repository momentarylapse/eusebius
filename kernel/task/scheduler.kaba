use common
use io.text
use io.io
use task.task
use task.manager
use time.timevalue
use time.timer
use irq.irq

#const SCHEDULER_STACK_SIZE = 8192

let TASK_SWITCH_DT = 5 # ms
let PERF_UPDATE_DT = 1000000000 # 1000 ns


class Scheduler
	

#	var static scheduler_task: Task*
#
	var static next_perf_calc: TimeValue
	var static running_pid: int

#	func static int_timer()
#		while true
#			#prints("(")
#			KernelTimer.tick()
#		
#			# IO-waits
#			process_waiting_tasks()
#			
#			update_times()
#			#prints(" ")
#		
#			# pick next task
#			int pid_next = get_next_task(running_pid)
#			reconnect_tasks(pid_next, scheduler_task)
#
#			#prints(")")
#
#			# allow more timer IRQs
#			irq.end_of_interrupt(0)
#			#outportb(0x20,0x20)
#
#			# return to (other) task
#			asm {
#				iret
#			}

	var static cur: Task*
	var static next: Task*
	
	func static run()
		running_pid = 0
		prints("starting scheduler\n")
		
		next = nil#&TaskManager.tasks[0]
		cur = nil

		KernelTimer.start()
		IrqManager.enable()

		asm{
			jmp $
		}


#		scheduler_task = TaskManager.add_task_kernel("scheduler", int_timer, SCHEDULER_STACK_SIZE, kernel_task)
#	
#		KernelTimer.init_interrupt(scheduler_task, TASK_SWITCH_DT)
#		next_perf_calc = KernelTimer.tv
#		next_perf_calc.inc_nanosec(PERF_UPDATE_DT)
#		scheduler_task.run_forced()

	func static @noframe int_timer()
		asm{
			cli
			# general purpose registers
			push rax
			push rbx
			push rcx
			push rdx
			push rbp
			push rdi
			push rsi
			push r8
			push r9
			push r10
			push r11
			push r12
			push r13
			push r14
			push r15
			# control registers 4*8b=32b
			mov eax, cr0
			push rax
			mov eax, cr2
			push rax
			mov eax, cr3
			push rax
			mov eax, cr4
			push rax
			#mov rax, cr8
			#push rax
			mov rax, rsp
			mov __temp_p__, rax
		}
		handle_irq(__temp_p__ as InterruptFrame*)
		asm{
			# control registers
			#add rsp, 0x20
			pop rax
			mov cr4, eax
			pop rax
			mov cr3, eax
			pop rax
			mov cr2, eax
			pop rax
			mov cr0, eax
			# general purpose registers
			pop r15
			pop r14
			pop r13
			pop r12
			pop r11
			pop r10
			pop r9
			pop r8
			pop rsi
			pop rdi
			pop rbp
			pop rdx
			pop rcx
			pop rbx
			pop rax
			#sti
			db 0x48
			iret
		}

	func static handle_irq(_frame: InterruptFrame*)
		IrqManager.mask(TIMER_IRQ)
		#prints("<timer>")
		let next_pid = get_next_task()
		if next_pid < 0
			panic("no running tasks")
		cur = &TaskManager.tasks[next_pid]
		for t in cur
			if t.first_time_running
				for frame in _frame
					frame.cs = 0x23
					frame.ss = 0x1b
					frame.rip = t.frame.rip
					frame.rsp = t.frame.rsp
					frame.rbp = t.frame.rsp
					frame.cr3 = t.frame.cr3
					#frame.cr4 = frame.cr4 | 0x200 # sse=1
					frame.rax = 0
					frame.rflags = 0x3200
					t.first_time_running = false
		IrqManager.eoi(TIMER_IRQ)
		IrqManager.unmask(TIMER_IRQ)


	# Scheduler
	func static get_next_task() -> int
		var pid0 = 0
		for c in cur
			pid0 = c.pid
		for i in pid0 + 1:MAX_TASKS
			if TaskManager.tasks[i].status == TaskStatus.RUNNING
				return i
		for i in 0:pid0+1
			if TaskManager.tasks[i].status == TaskStatus.RUNNING
				return i
		for i in 0:5
			printi(int(TaskManager.tasks[i].status))
		return -1#TaskManager.idle_task.pid

#	func static process_waiting_tasks()
#		for t in TaskManager.tasks
#			if t.status == TASK_STATUS_WAITING
#				if t.waiting_mode == WAITING_MODE_TIME
#					TimeValue *rem = &t.waiting_param_i1
#					rem.dec_nanosec(KernelTimer.dt_nanosec)
#					if rem.sec < 0
#						t.tss.eax = 0 # return 0
#						t.activate()
#				else
#					t.do_wait_update()
#
#
#	func static reconnect_tasks(pid_next: int, out irq_task: Task)
#		#int pid_cur = irq_task.get_prev_task()
#		TaskManager.gdt[TaskManager.tasks[running_pid].desc].set_busy(false)
#		TaskManager.gdt[TaskManager.tasks[pid_next].desc].set_busy(true)
#		irq_task.tss.prev = (pid_next + NUM_PRE_GDT_ENTRIES) << 3
#		running_pid = pid_next
#		#prints("<rec ")
#	#	printi pid_next
#	#	prints(">")
#
#	func static update_times()
#		TaskManager.tasks[running_pid].time_all.inc_nanosec(KernelTimer.dt_nanosec)
#		TaskManager.tasks[running_pid].time_temp.inc_nanosec(KernelTimer.dt_nanosec)
#	
#		if !KernelTimer.tv.is_before(next_perf_calc)
#			next_perf_calc.inc_nanosec(PERF_UPDATE_DT)
#			for t in TaskManager.tasks
#				t.cpu_load = t.time_temp.nanosec / (PERF_UPDATE_DT / 1000)
#				t.time_temp.clear()
#